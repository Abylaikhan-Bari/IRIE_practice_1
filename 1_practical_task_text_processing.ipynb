{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–µ –∑–∞–¥–∞–Ω–∏–µ 1: –í–≤–µ–¥–µ–Ω–∏–µ –≤ NLTK, spaCy –∏ –æ–±—Ä–∞–±–æ—Ç–∫—É —Ç–µ–∫—Å—Ç–∞\n",
    "**–ö—É—Ä—Å:** Information Retrieval & Information Extraction\n",
    "**–ê–≤—Ç–æ—Ä:** –ê–±—ã–ª–∞–π—Ö–∞–Ω –ë–∞—Ä–∏\n",
    "\n",
    "–≠—Ç–æ—Ç –æ—Ç—á–µ—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—é –æ—Å–Ω–æ–≤–Ω—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞:\n",
    "‚úÖ –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è (NLTK, spaCy)\n",
    "‚úÖ –£–¥–∞–ª–µ–Ω–∏–µ —Å—Ç–æ–ø-—Å–ª–æ–≤ (NLTK, spaCy)\n",
    "‚úÖ –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n",
    "‚úÖ –ê–Ω–∞–ª–∏–∑ —Ä–∞–±–æ—Ç—ã —Å —Ä—É—Å—Å–∫–∏–º —Ç–µ–∫—Å—Ç–æ–º\n"
   ],
   "id": "cd9fdad5c79e3c44"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T11:10:24.207110Z",
     "start_time": "2025-02-13T11:03:48.104277Z"
    }
   },
   "cell_type": "code",
   "source": [
    "!pip install nltk spacy\n",
    "!python -m spacy download en_core_web_sm\n",
    "!python -m spacy download ru_core_news_sm\n"
   ],
   "id": "1be84c1c8ce43ef7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in ./.venv/lib/python3.9/site-packages (3.9.1)\r\n",
      "Requirement already satisfied: spacy in ./.venv/lib/python3.9/site-packages (3.8.3)\r\n",
      "Requirement already satisfied: click in ./.venv/lib/python3.9/site-packages (from nltk) (8.1.8)\r\n",
      "Requirement already satisfied: joblib in ./.venv/lib/python3.9/site-packages (from nltk) (1.4.2)\r\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./.venv/lib/python3.9/site-packages (from nltk) (2024.11.6)\r\n",
      "Requirement already satisfied: tqdm in ./.venv/lib/python3.9/site-packages (from nltk) (4.67.1)\r\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in ./.venv/lib/python3.9/site-packages (from spacy) (3.0.12)\r\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in ./.venv/lib/python3.9/site-packages (from spacy) (1.0.5)\r\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in ./.venv/lib/python3.9/site-packages (from spacy) (1.0.12)\r\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in ./.venv/lib/python3.9/site-packages (from spacy) (2.0.11)\r\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in ./.venv/lib/python3.9/site-packages (from spacy) (3.0.9)\r\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.0 in ./.venv/lib/python3.9/site-packages (from spacy) (8.3.4)\r\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in ./.venv/lib/python3.9/site-packages (from spacy) (1.1.3)\r\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in ./.venv/lib/python3.9/site-packages (from spacy) (2.5.1)\r\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in ./.venv/lib/python3.9/site-packages (from spacy) (2.0.10)\r\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in ./.venv/lib/python3.9/site-packages (from spacy) (0.4.1)\r\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in ./.venv/lib/python3.9/site-packages (from spacy) (0.15.1)\r\n",
      "Requirement already satisfied: numpy>=1.19.0 in ./.venv/lib/python3.9/site-packages (from spacy) (2.0.2)\r\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in ./.venv/lib/python3.9/site-packages (from spacy) (2.32.3)\r\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in ./.venv/lib/python3.9/site-packages (from spacy) (2.10.6)\r\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.9/site-packages (from spacy) (3.1.5)\r\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.9/site-packages (from spacy) (68.2.0)\r\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.9/site-packages (from spacy) (24.2)\r\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in ./.venv/lib/python3.9/site-packages (from spacy) (3.5.0)\r\n",
      "Requirement already satisfied: language-data>=1.2 in ./.venv/lib/python3.9/site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\r\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in ./.venv/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.27.2)\r\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in ./.venv/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.3.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.1.31)\r\n",
      "Requirement already satisfied: blis<1.3.0,>=1.2.0 in ./.venv/lib/python3.9/site-packages (from thinc<8.4.0,>=8.3.0->spacy) (1.2.0)\r\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in ./.venv/lib/python3.9/site-packages (from thinc<8.4.0,>=8.3.0->spacy) (0.1.5)\r\n",
      "Requirement already satisfied: shellingham>=1.3.0 in ./.venv/lib/python3.9/site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\r\n",
      "Requirement already satisfied: rich>=10.11.0 in ./.venv/lib/python3.9/site-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\r\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in ./.venv/lib/python3.9/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.20.0)\r\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in ./.venv/lib/python3.9/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.9/site-packages (from jinja2->spacy) (3.0.2)\r\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in ./.venv/lib/python3.9/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./.venv/lib/python3.9/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./.venv/lib/python3.9/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.1)\r\n",
      "Requirement already satisfied: wrapt in ./.venv/lib/python3.9/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in ./.venv/lib/python3.9/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\r\n",
      "/Users/aikei/PycharmProjects/IRIE_practice_1/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\r\n",
      "  warnings.warn(\r\n",
      "Collecting en-core-web-sm==3.8.0\r\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\r\n",
      "\u001B[2K     \u001B[91m‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[90m‚ï∫\u001B[0m\u001B[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m \u001B[32m1.3/12.8 MB\u001B[0m \u001B[31m37.6 kB/s\u001B[0m eta \u001B[36m0:05:07\u001B[0m\r\n",
      "\u001B[?25h\u001B[31mERROR: Exception:\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/Users/aikei/PycharmProjects/IRIE_practice_1/.venv/lib/python3.9/site-packages/pip/_vendor/urllib3/response.py\", line 438, in _error_catcher\r\n",
      "    yield\r\n",
      "  File \"/Users/aikei/PycharmProjects/IRIE_practice_1/.venv/lib/python3.9/site-packages/pip/_vendor/urllib3/response.py\", line 561, in read\r\n",
      "    data = self._fp_read(amt) if not fp_closed else b\"\"\r\n",
      "  File \"/Users/aikei/PycharmProjects/IRIE_practice_1/.venv/lib/python3.9/site-packages/pip/_vendor/urllib3/response.py\", line 527, in _fp_read\r\n",
      "    return self._fp.read(amt) if amt is not None else self._fp.read()\r\n",
      "  File \"/Users/aikei/PycharmProjects/IRIE_practice_1/.venv/lib/python3.9/site-packages/pip/_vendor/cachecontrol/filewrapper.py\", line 98, in read\r\n",
      "    data: bytes = self.__fp.read(amt)\r\n",
      "  File \"/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py\", line 459, in read\r\n",
      "    n = self.readinto(b)\r\n",
      "  File \"/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py\", line 503, in readinto\r\n",
      "    n = self.fp.readinto(b)\r\n",
      "  File \"/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/socket.py\", line 704, in readinto\r\n",
      "    return self._sock.recv_into(b)\r\n",
      "  File \"/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/ssl.py\", line 1241, in recv_into\r\n",
      "    return self.read(nbytes, buffer)\r\n",
      "  File \"/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/ssl.py\", line 1099, in read\r\n",
      "    return self._sslobj.read(len, buffer)\r\n",
      "socket.timeout: The read operation timed out\r\n",
      "\r\n",
      "During handling of the above exception, another exception occurred:\r\n",
      "\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/Users/aikei/PycharmProjects/IRIE_practice_1/.venv/lib/python3.9/site-packages/pip/_internal/cli/base_command.py\", line 106, in _run_wrapper\r\n",
      "    status = _inner_run()\r\n",
      "  File \"/Users/aikei/PycharmProjects/IRIE_practice_1/.venv/lib/python3.9/site-packages/pip/_internal/cli/base_command.py\", line 97, in _inner_run\r\n",
      "    return self.run(options, args)\r\n",
      "  File \"/Users/aikei/PycharmProjects/IRIE_practice_1/.venv/lib/python3.9/site-packages/pip/_internal/cli/req_command.py\", line 67, in wrapper\r\n",
      "    return func(self, options, args)\r\n",
      "  File \"/Users/aikei/PycharmProjects/IRIE_practice_1/.venv/lib/python3.9/site-packages/pip/_internal/commands/install.py\", line 386, in run\r\n",
      "    requirement_set = resolver.resolve(\r\n",
      "  File \"/Users/aikei/PycharmProjects/IRIE_practice_1/.venv/lib/python3.9/site-packages/pip/_internal/resolution/resolvelib/resolver.py\", line 76, in resolve\r\n",
      "    collected = self.factory.collect_root_requirements(root_reqs)\r\n",
      "  File \"/Users/aikei/PycharmProjects/IRIE_practice_1/.venv/lib/python3.9/site-packages/pip/_internal/resolution/resolvelib/factory.py\", line 545, in collect_root_requirements\r\n",
      "    reqs = list(\r\n",
      "  File \"/Users/aikei/PycharmProjects/IRIE_practice_1/.venv/lib/python3.9/site-packages/pip/_internal/resolution/resolvelib/factory.py\", line 501, in _make_requirements_from_install_req\r\n",
      "    cand = self._make_base_candidate_from_link(\r\n",
      "  File \"/Users/aikei/PycharmProjects/IRIE_practice_1/.venv/lib/python3.9/site-packages/pip/_internal/resolution/resolvelib/factory.py\", line 233, in _make_base_candidate_from_link\r\n",
      "    self._link_candidate_cache[link] = LinkCandidate(\r\n",
      "  File \"/Users/aikei/PycharmProjects/IRIE_practice_1/.venv/lib/python3.9/site-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 304, in __init__\r\n",
      "    super().__init__(\r\n",
      "  File \"/Users/aikei/PycharmProjects/IRIE_practice_1/.venv/lib/python3.9/site-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 159, in __init__\r\n",
      "    self.dist = self._prepare()\r\n",
      "  File \"/Users/aikei/PycharmProjects/IRIE_practice_1/.venv/lib/python3.9/site-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 236, in _prepare\r\n",
      "    dist = self._prepare_distribution()\r\n",
      "  File \"/Users/aikei/PycharmProjects/IRIE_practice_1/.venv/lib/python3.9/site-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 315, in _prepare_distribution\r\n",
      "    return preparer.prepare_linked_requirement(self._ireq, parallel_builds=True)\r\n",
      "  File \"/Users/aikei/PycharmProjects/IRIE_practice_1/.venv/lib/python3.9/site-packages/pip/_internal/operations/prepare.py\", line 527, in prepare_linked_requirement\r\n",
      "    return self._prepare_linked_requirement(req, parallel_builds)\r\n",
      "  File \"/Users/aikei/PycharmProjects/IRIE_practice_1/.venv/lib/python3.9/site-packages/pip/_internal/operations/prepare.py\", line 598, in _prepare_linked_requirement\r\n",
      "    local_file = unpack_url(\r\n",
      "  File \"/Users/aikei/PycharmProjects/IRIE_practice_1/.venv/lib/python3.9/site-packages/pip/_internal/operations/prepare.py\", line 170, in unpack_url\r\n",
      "    file = get_http_url(\r\n",
      "  File \"/Users/aikei/PycharmProjects/IRIE_practice_1/.venv/lib/python3.9/site-packages/pip/_internal/operations/prepare.py\", line 111, in get_http_url\r\n",
      "    from_path, content_type = download(link, temp_dir.path)\r\n",
      "  File \"/Users/aikei/PycharmProjects/IRIE_practice_1/.venv/lib/python3.9/site-packages/pip/_internal/network/download.py\", line 148, in __call__\r\n",
      "    for chunk in chunks:\r\n",
      "  File \"/Users/aikei/PycharmProjects/IRIE_practice_1/.venv/lib/python3.9/site-packages/pip/_internal/cli/progress_bars.py\", line 55, in _rich_progress_bar\r\n",
      "    for chunk in iterable:\r\n",
      "  File \"/Users/aikei/PycharmProjects/IRIE_practice_1/.venv/lib/python3.9/site-packages/pip/_internal/network/utils.py\", line 65, in response_chunks\r\n",
      "    for chunk in response.raw.stream(\r\n",
      "  File \"/Users/aikei/PycharmProjects/IRIE_practice_1/.venv/lib/python3.9/site-packages/pip/_vendor/urllib3/response.py\", line 622, in stream\r\n",
      "    data = self.read(amt=amt, decode_content=decode_content)\r\n",
      "  File \"/Users/aikei/PycharmProjects/IRIE_practice_1/.venv/lib/python3.9/site-packages/pip/_vendor/urllib3/response.py\", line 587, in read\r\n",
      "    raise IncompleteRead(self._fp_bytes_read, self.length_remaining)\r\n",
      "  File \"/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/contextlib.py\", line 135, in __exit__\r\n",
      "    self.gen.throw(type, value, traceback)\r\n",
      "  File \"/Users/aikei/PycharmProjects/IRIE_practice_1/.venv/lib/python3.9/site-packages/pip/_vendor/urllib3/response.py\", line 443, in _error_catcher\r\n",
      "    raise ReadTimeoutError(self._pool, None, \"Read timed out.\")\r\n",
      "pip._vendor.urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='objects.githubusercontent.com', port=443): Read timed out.\u001B[0m\u001B[31m\r\n",
      "\u001B[0m/Users/aikei/PycharmProjects/IRIE_practice_1/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\r\n",
      "  warnings.warn(\r\n",
      "Collecting ru-core-news-sm==3.8.0\r\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/ru_core_news_sm-3.8.0/ru_core_news_sm-3.8.0-py3-none-any.whl (15.3 MB)\r\n",
      "\u001B[2K     \u001B[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m \u001B[32m15.3/15.3 MB\u001B[0m \u001B[31m42.8 kB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:02\u001B[0m00:13\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: pymorphy3>=1.0.0 in ./.venv/lib/python3.9/site-packages (from ru-core-news-sm==3.8.0) (2.0.2)\r\n",
      "Requirement already satisfied: dawg-python>=0.7.1 in ./.venv/lib/python3.9/site-packages (from pymorphy3>=1.0.0->ru-core-news-sm==3.8.0) (0.7.2)\r\n",
      "Requirement already satisfied: pymorphy3-dicts-ru in ./.venv/lib/python3.9/site-packages (from pymorphy3>=1.0.0->ru-core-news-sm==3.8.0) (2.4.417150.4580142)\r\n",
      "\u001B[38;5;2m‚úî Download and installation successful\u001B[0m\r\n",
      "You can now load the package via spacy.load('ru_core_news_sm')\r\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T11:25:07.042691Z",
     "start_time": "2025-02-13T11:25:06.382146Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import nltk\n",
    "import spacy\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# –ó–∞–≥—Ä—É–∑–∫–∞ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö —Ä–µ—Å—É—Ä—Å–æ–≤ NLTK\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π spaCy\n",
    "nlp_en = spacy.load(\"en_core_web_sm\")\n",
    "nlp_ru = spacy.load(\"ru_core_news_sm\")\n"
   ],
   "id": "af8a43675c2ebbf9",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/aikei/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/aikei/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T11:25:13.866929Z",
     "start_time": "2025-02-13T11:25:13.863630Z"
    }
   },
   "cell_type": "code",
   "source": [
    "text_en = \"\"\"\n",
    "Natural Language Processing (NLP) is an exciting field of artificial intelligence.\n",
    "It enables computers to understand, interpret, and respond to human language.\n",
    "Many applications, such as chatbots, translation services, and sentiment analysis,\n",
    "rely on NLP technology.\n",
    "Furthermore, machine learning and deep learning techniques have significantly improved NLP capabilities.\n",
    "\"\"\"\n",
    "\n",
    "text_ru = \"\"\"\n",
    "–û–±—Ä–∞–±–æ—Ç–∫–∞ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ —è–∑—ã–∫–∞ ‚Äî —ç—Ç–æ —É–≤–ª–µ–∫–∞—Ç–µ–ª—å–Ω–∞—è –æ–±–ª–∞—Å—Ç—å –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞.\n",
    "–û–Ω–∞ –ø–æ–∑–≤–æ–ª—è–µ—Ç –∫–æ–º–ø—å—é—Ç–µ—Ä–∞–º –ø–æ–Ω–∏–º–∞—Ç—å, –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä–æ–≤–∞—Ç—å –∏ –æ—Ç–≤–µ—á–∞—Ç—å –Ω–∞ —á–µ–ª–æ–≤–µ—á–µ—Å–∫–∏–π —è–∑—ã–∫.\n",
    "–ú–Ω–æ–≥–∏–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è, —Ç–∞–∫–∏–µ –∫–∞–∫ —á–∞—Ç-–±–æ—Ç—ã, –ø–µ—Ä–µ–≤–æ–¥—á–∏–∫–∏ –∏ –∞–Ω–∞–ª–∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–π, –∏—Å–ø–æ–ª—å–∑—É—é—Ç —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏ NLP.\n",
    "–ö—Ä–æ–º–µ —Ç–æ–≥–æ, –º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –∏ –≥–ª—É–±–æ–∫–∏–µ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏ –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ —É–ª—É—á—à–∏–ª–∏ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞.\n",
    "\"\"\"\n",
    "\n",
    "print(\"English Text:\", text_en)\n",
    "print(\"Russian Text:\", text_ru)\n"
   ],
   "id": "47a803da1fa34bdf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Text: \n",
      "Natural Language Processing (NLP) is an exciting field of artificial intelligence.\n",
      "It enables computers to understand, interpret, and respond to human language.\n",
      "Many applications, such as chatbots, translation services, and sentiment analysis,\n",
      "rely on NLP technology.\n",
      "Furthermore, machine learning and deep learning techniques have significantly improved NLP capabilities.\n",
      "\n",
      "Russian Text: \n",
      "–û–±—Ä–∞–±–æ—Ç–∫–∞ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ —è–∑—ã–∫–∞ ‚Äî —ç—Ç–æ —É–≤–ª–µ–∫–∞—Ç–µ–ª—å–Ω–∞—è –æ–±–ª–∞—Å—Ç—å –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞.\n",
      "–û–Ω–∞ –ø–æ–∑–≤–æ–ª—è–µ—Ç –∫–æ–º–ø—å—é—Ç–µ—Ä–∞–º –ø–æ–Ω–∏–º–∞—Ç—å, –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä–æ–≤–∞—Ç—å –∏ –æ—Ç–≤–µ—á–∞—Ç—å –Ω–∞ —á–µ–ª–æ–≤–µ—á–µ—Å–∫–∏–π —è–∑—ã–∫.\n",
      "–ú–Ω–æ–≥–∏–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è, —Ç–∞–∫–∏–µ –∫–∞–∫ —á–∞—Ç-–±–æ—Ç—ã, –ø–µ—Ä–µ–≤–æ–¥—á–∏–∫–∏ –∏ –∞–Ω–∞–ª–∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–π, –∏—Å–ø–æ–ª—å–∑—É—é—Ç —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏ NLP.\n",
      "–ö—Ä–æ–º–µ —Ç–æ–≥–æ, –º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –∏ –≥–ª—É–±–æ–∫–∏–µ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏ –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ —É–ª—É—á—à–∏–ª–∏ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞.\n",
      "\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T11:25:20.818072Z",
     "start_time": "2025-02-13T11:25:20.783780Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Task 1: Tokenization ---\n",
    "# NLTK Tokenization\n",
    "tokens_nltk_en = word_tokenize(text_en)\n",
    "tokens_nltk_ru = word_tokenize(text_ru, language=\"russian\")\n",
    "\n",
    "# spaCy Tokenization\n",
    "doc_en = nlp_en(text_en)\n",
    "tokens_spacy_en = [token.text for token in doc_en]\n",
    "\n",
    "doc_ru = nlp_ru(text_ru)\n",
    "tokens_spacy_ru = [token.text for token in doc_ru]\n",
    "\n",
    "print(\"üîπ English Tokenization (NLTK):\", tokens_nltk_en)\n",
    "print(\"üîπ English Tokenization (spaCy):\", tokens_spacy_en)\n",
    "print(\"üîπ Russian Tokenization (NLTK):\", tokens_nltk_ru)\n",
    "print(\"üîπ Russian Tokenization (spaCy):\", tokens_spacy_ru)\n"
   ],
   "id": "89ee33718ca0fb88",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ English Tokenization (NLTK): ['Natural', 'Language', 'Processing', '(', 'NLP', ')', 'is', 'an', 'exciting', 'field', 'of', 'artificial', 'intelligence', '.', 'It', 'enables', 'computers', 'to', 'understand', ',', 'interpret', ',', 'and', 'respond', 'to', 'human', 'language', '.', 'Many', 'applications', ',', 'such', 'as', 'chatbots', ',', 'translation', 'services', ',', 'and', 'sentiment', 'analysis', ',', 'rely', 'on', 'NLP', 'technology', '.', 'Furthermore', ',', 'machine', 'learning', 'and', 'deep', 'learning', 'techniques', 'have', 'significantly', 'improved', 'NLP', 'capabilities', '.']\n",
      "üîπ English Tokenization (spaCy): ['\\n', 'Natural', 'Language', 'Processing', '(', 'NLP', ')', 'is', 'an', 'exciting', 'field', 'of', 'artificial', 'intelligence', '.', '\\n', 'It', 'enables', 'computers', 'to', 'understand', ',', 'interpret', ',', 'and', 'respond', 'to', 'human', 'language', '.', '\\n', 'Many', 'applications', ',', 'such', 'as', 'chatbots', ',', 'translation', 'services', ',', 'and', 'sentiment', 'analysis', ',', '\\n', 'rely', 'on', 'NLP', 'technology', '.', '\\n', 'Furthermore', ',', 'machine', 'learning', 'and', 'deep', 'learning', 'techniques', 'have', 'significantly', 'improved', 'NLP', 'capabilities', '.', '\\n']\n",
      "üîπ Russian Tokenization (NLTK): ['–û–±—Ä–∞–±–æ—Ç–∫–∞', '–µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ', '—è–∑—ã–∫–∞', '‚Äî', '—ç—Ç–æ', '—É–≤–ª–µ–∫–∞—Ç–µ–ª—å–Ω–∞—è', '–æ–±–ª–∞—Å—Ç—å', '–∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ', '–∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞', '.', '–û–Ω–∞', '–ø–æ–∑–≤–æ–ª—è–µ—Ç', '–∫–æ–º–ø—å—é—Ç–µ—Ä–∞–º', '–ø–æ–Ω–∏–º–∞—Ç—å', ',', '–∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä–æ–≤–∞—Ç—å', '–∏', '–æ—Ç–≤–µ—á–∞—Ç—å', '–Ω–∞', '—á–µ–ª–æ–≤–µ—á–µ—Å–∫–∏–π', '—è–∑—ã–∫', '.', '–ú–Ω–æ–≥–∏–µ', '–ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è', ',', '—Ç–∞–∫–∏–µ', '–∫–∞–∫', '—á–∞—Ç-–±–æ—Ç—ã', ',', '–ø–µ—Ä–µ–≤–æ–¥—á–∏–∫–∏', '–∏', '–∞–Ω–∞–ª–∏–∑', '–Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–π', ',', '–∏—Å–ø–æ–ª—å–∑—É—é—Ç', '—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏', 'NLP', '.', '–ö—Ä–æ–º–µ', '—Ç–æ–≥–æ', ',', '–º–∞—à–∏–Ω–Ω–æ–µ', '–æ–±—É—á–µ–Ω–∏–µ', '–∏', '–≥–ª—É–±–æ–∫–∏–µ', '–Ω–µ–π—Ä–æ—Å–µ—Ç–∏', '–∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ', '—É–ª—É—á—à–∏–ª–∏', '–≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏', '–æ–±—Ä–∞–±–æ—Ç–∫–∏', '—Ç–µ–∫—Å—Ç–∞', '.']\n",
      "üîπ Russian Tokenization (spaCy): ['\\n', '–û–±—Ä–∞–±–æ—Ç–∫–∞', '–µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ', '—è–∑—ã–∫–∞', '‚Äî', '—ç—Ç–æ', '—É–≤–ª–µ–∫–∞—Ç–µ–ª—å–Ω–∞—è', '–æ–±–ª–∞—Å—Ç—å', '–∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ', '–∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞', '.', '\\n', '–û–Ω–∞', '–ø–æ–∑–≤–æ–ª—è–µ—Ç', '–∫–æ–º–ø—å—é—Ç–µ—Ä–∞–º', '–ø–æ–Ω–∏–º–∞—Ç—å', ',', '–∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä–æ–≤–∞—Ç—å', '–∏', '–æ—Ç–≤–µ—á–∞—Ç—å', '–Ω–∞', '—á–µ–ª–æ–≤–µ—á–µ—Å–∫–∏–π', '—è–∑—ã–∫', '.', '\\n', '–ú–Ω–æ–≥–∏–µ', '–ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è', ',', '—Ç–∞–∫–∏–µ', '–∫–∞–∫', '—á–∞—Ç', '-', '–±–æ—Ç—ã', ',', '–ø–µ—Ä–µ–≤–æ–¥—á–∏–∫–∏', '–∏', '–∞–Ω–∞–ª–∏–∑', '–Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–π', ',', '–∏—Å–ø–æ–ª—å–∑—É—é—Ç', '—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏', 'NLP', '.', '\\n', '–ö—Ä–æ–º–µ', '—Ç–æ–≥–æ', ',', '–º–∞—à–∏–Ω–Ω–æ–µ', '–æ–±—É—á–µ–Ω–∏–µ', '–∏', '–≥–ª—É–±–æ–∫–∏–µ', '–Ω–µ–π—Ä–æ—Å–µ—Ç–∏', '–∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ', '—É–ª—É—á—à–∏–ª–∏', '–≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏', '–æ–±—Ä–∞–±–æ—Ç–∫–∏', '—Ç–µ–∫—Å—Ç–∞', '.', '\\n']\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T11:25:25.974959Z",
     "start_time": "2025-02-13T11:25:25.969166Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Task 2: Stop-word Removal ---\n",
    "# NLTK Stop-word removal\n",
    "stop_words_en = set(stopwords.words('english'))\n",
    "filtered_words_nltk_en = [word for word in tokens_nltk_en if word.lower() not in stop_words_en]\n",
    "\n",
    "stop_words_ru = set(stopwords.words('russian'))\n",
    "filtered_words_nltk_ru = [word for word in tokens_nltk_ru if word.lower() not in stop_words_ru]\n",
    "\n",
    "# spaCy Stop-word removal\n",
    "filtered_words_spacy_en = [token.text for token in doc_en if not token.is_stop]\n",
    "filtered_words_spacy_ru = [token.text for token in doc_ru if not token.is_stop]\n",
    "\n",
    "print(\"üîπ English Stop-word Removal (NLTK):\", filtered_words_nltk_en)\n",
    "print(\"üîπ English Stop-word Removal (spaCy):\", filtered_words_spacy_en)\n",
    "print(\"üîπ Russian Stop-word Removal (NLTK):\", filtered_words_nltk_ru)\n",
    "print(\"üîπ Russian Stop-word Removal (spaCy):\", filtered_words_spacy_ru)\n"
   ],
   "id": "11a50381eff8db35",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ English Stop-word Removal (NLTK): ['Natural', 'Language', 'Processing', '(', 'NLP', ')', 'exciting', 'field', 'artificial', 'intelligence', '.', 'enables', 'computers', 'understand', ',', 'interpret', ',', 'respond', 'human', 'language', '.', 'Many', 'applications', ',', 'chatbots', ',', 'translation', 'services', ',', 'sentiment', 'analysis', ',', 'rely', 'NLP', 'technology', '.', 'Furthermore', ',', 'machine', 'learning', 'deep', 'learning', 'techniques', 'significantly', 'improved', 'NLP', 'capabilities', '.']\n",
      "üîπ English Stop-word Removal (spaCy): ['\\n', 'Natural', 'Language', 'Processing', '(', 'NLP', ')', 'exciting', 'field', 'artificial', 'intelligence', '.', '\\n', 'enables', 'computers', 'understand', ',', 'interpret', ',', 'respond', 'human', 'language', '.', '\\n', 'applications', ',', 'chatbots', ',', 'translation', 'services', ',', 'sentiment', 'analysis', ',', '\\n', 'rely', 'NLP', 'technology', '.', '\\n', 'Furthermore', ',', 'machine', 'learning', 'deep', 'learning', 'techniques', 'significantly', 'improved', 'NLP', 'capabilities', '.', '\\n']\n",
      "üîπ Russian Stop-word Removal (NLTK): ['–û–±—Ä–∞–±–æ—Ç–∫–∞', '–µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ', '—è–∑—ã–∫–∞', '‚Äî', '—ç—Ç–æ', '—É–≤–ª–µ–∫–∞—Ç–µ–ª—å–Ω–∞—è', '–æ–±–ª–∞—Å—Ç—å', '–∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ', '–∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞', '.', '–ø–æ–∑–≤–æ–ª—è–µ—Ç', '–∫–æ–º–ø—å—é—Ç–µ—Ä–∞–º', '–ø–æ–Ω–∏–º–∞—Ç—å', ',', '–∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä–æ–≤–∞—Ç—å', '–æ—Ç–≤–µ—á–∞—Ç—å', '—á–µ–ª–æ–≤–µ—á–µ—Å–∫–∏–π', '—è–∑—ã–∫', '.', '–ú–Ω–æ–≥–∏–µ', '–ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è', ',', '—Ç–∞–∫–∏–µ', '—á–∞—Ç-–±–æ—Ç—ã', ',', '–ø–µ—Ä–µ–≤–æ–¥—á–∏–∫–∏', '–∞–Ω–∞–ª–∏–∑', '–Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–π', ',', '–∏—Å–ø–æ–ª—å–∑—É—é—Ç', '—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏', 'NLP', '.', '–ö—Ä–æ–º–µ', ',', '–º–∞—à–∏–Ω–Ω–æ–µ', '–æ–±—É—á–µ–Ω–∏–µ', '–≥–ª—É–±–æ–∫–∏–µ', '–Ω–µ–π—Ä–æ—Å–µ—Ç–∏', '–∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ', '—É–ª—É—á—à–∏–ª–∏', '–≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏', '–æ–±—Ä–∞–±–æ—Ç–∫–∏', '—Ç–µ–∫—Å—Ç–∞', '.']\n",
      "üîπ Russian Stop-word Removal (spaCy): ['\\n', '–û–±—Ä–∞–±–æ—Ç–∫–∞', '–µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ', '—è–∑—ã–∫–∞', '‚Äî', '—É–≤–ª–µ–∫–∞—Ç–µ–ª—å–Ω–∞—è', '–æ–±–ª–∞—Å—Ç—å', '–∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ', '–∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞', '.', '\\n', '–ø–æ–∑–≤–æ–ª—è–µ—Ç', '–∫–æ–º–ø—å—é—Ç–µ—Ä–∞–º', '–ø–æ–Ω–∏–º–∞—Ç—å', ',', '–∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä–æ–≤–∞—Ç—å', '–æ—Ç–≤–µ—á–∞—Ç—å', '—á–µ–ª–æ–≤–µ—á–µ—Å–∫–∏–π', '—è–∑—ã–∫', '.', '\\n', '–ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è', ',', '—á–∞—Ç', '-', '–±–æ—Ç—ã', ',', '–ø–µ—Ä–µ–≤–æ–¥—á–∏–∫–∏', '–∞–Ω–∞–ª–∏–∑', '–Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–π', ',', '–∏—Å–ø–æ–ª—å–∑—É—é—Ç', '—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏', 'NLP', '.', '\\n', ',', '–º–∞—à–∏–Ω–Ω–æ–µ', '–æ–±—É—á–µ–Ω–∏–µ', '–≥–ª—É–±–æ–∫–∏–µ', '–Ω–µ–π—Ä–æ—Å–µ—Ç–∏', '–∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ', '—É–ª—É—á—à–∏–ª–∏', '–≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏', '–æ–±—Ä–∞–±–æ—Ç–∫–∏', '—Ç–µ–∫—Å—Ç–∞', '.', '\\n']\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T11:25:31.147613Z",
     "start_time": "2025-02-13T11:25:31.143665Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"üîç Words removed by NLTK but kept by spaCy (English):\", set(filtered_words_nltk_en) - set(filtered_words_spacy_en))\n",
    "print(\"üîç Words removed by spaCy but kept by NLTK (English):\", set(filtered_words_spacy_en) - set(filtered_words_nltk_en))\n",
    "\n",
    "print(\"üîç Words removed by NLTK but kept by spaCy (Russian):\", set(filtered_words_nltk_ru) - set(filtered_words_spacy_ru))\n",
    "print(\"üîç Words removed by spaCy but kept by NLTK (Russian):\", set(filtered_words_spacy_ru) - set(filtered_words_nltk_ru))\n"
   ],
   "id": "73224041273b1ff8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Words removed by NLTK but kept by spaCy (English): {'Many'}\n",
      "üîç Words removed by spaCy but kept by NLTK (English): {'\\n'}\n",
      "üîç Words removed by NLTK but kept by spaCy (Russian): {'—á–∞—Ç-–±–æ—Ç—ã', '–ö—Ä–æ–º–µ', '–ú–Ω–æ–≥–∏–µ', '—Ç–∞–∫–∏–µ', '—ç—Ç–æ'}\n",
      "üîç Words removed by spaCy but kept by NLTK (Russian): {'\\n', '—á–∞—Ç', '–±–æ—Ç—ã', '-'}\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## –í—ã–≤–æ–¥—ã\n",
    "1. **–¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è**:\n",
    "   - NLTK —Ä–∞–∑–±–∏–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç –ø—Ä–æ—Å—Ç–æ –Ω–∞ —Å–ª–æ–≤–∞ –∏ –∑–Ω–∞–∫–∏ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è.\n",
    "   - spaCy –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –±–æ–ª–µ–µ —Å–ª–æ–∂–Ω—ã–µ –∞–ª–≥–æ—Ä–∏—Ç–º—ã –∏ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∑–Ω–∞–∫–∏ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è.\n",
    "\n",
    "2. **–£–¥–∞–ª–µ–Ω–∏–µ —Å—Ç–æ–ø-—Å–ª–æ–≤**:\n",
    "   - NLTK –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ —Å—Ç–æ–ø-—Å–ª–æ–≤.\n",
    "   - spaCy –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π —Å–ø–∏—Å–æ–∫, –æ—Å–Ω–æ–≤–∞–Ω–Ω—ã–π –Ω–∞ –º–æ–¥–µ–ª—è—Ö.\n",
    "\n",
    "3. **–†–∞–∑–ª–∏—á–∏—è –º–µ–∂–¥—É NLTK –∏ spaCy**:\n",
    "   - spaCy —á–∞—â–µ –æ—Å—Ç–∞–≤–ª—è–µ—Ç –≤–∞–∂–Ω—ã–µ —Å–ª–æ–≤–∞, –¥–∞–∂–µ –µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å –≤ —Å–ø–∏—Å–∫–µ —Å—Ç–æ–ø-—Å–ª–æ–≤ NLTK.\n",
    "   - –í —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ spaCy —Ä–∞–±–æ—Ç–∞–µ—Ç —Ç–æ—á–Ω–µ–µ, —Ç–∞–∫ –∫–∞–∫ —É NLTK –º–æ–≥—É—Ç –æ—Ç—Å—É—Ç—Å—Ç–≤–æ–≤–∞—Ç—å –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ —Å–ª–æ–≤–∞.\n",
    "\n",
    "4. **–í—ã–≤–æ–¥ –ø–æ —Ä—É—Å—Å–∫–æ–º—É —è–∑—ã–∫—É**:\n",
    "   - NLTK —Ö—É–∂–µ —Å–ø—Ä–∞–≤–ª—è–µ—Ç—Å—è —Å —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–µ–π —Ä—É—Å—Å–∫–æ–≥–æ —Ç–µ–∫—Å—Ç–∞.\n",
    "   - spaCy –ª—É—á—à–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–µ—Ç –≥—Ä–∞–Ω–∏—Ü—ã —Å–ª–æ–≤ –∏ –∑–Ω–∞–∫–∏ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è.\n",
    "\n",
    "**üí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è:** –î–ª—è –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–∞ –∑–∞–¥–∞—á spaCy –±–æ–ª–µ–µ —É–¥–æ–±–µ–Ω, –æ—Å–æ–±–µ–Ω–Ω–æ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —Ä—É—Å—Å–∫–∏–º —Ç–µ–∫—Å—Ç–æ–º.\n"
   ],
   "id": "78cdab209104bf1b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "ad5762ffbd73be75"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
